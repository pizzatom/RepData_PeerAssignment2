---
title: "Investigating Population Health and Economic Consequences of Weather Events in the United States"
author: "Thomas R Nudell"
date: "January 4, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(dplyr)
library(tidyr)
```


## Summary

This data analysis addresses the two following questions:

1. Across the United States, which types of events (as indicated in the `EVTYPE` variable) are most harmful with respect to population health?
2. Across the United States, which types of events have the greatest economic consequences?

[//]: # (Summary of analysis)

## Data Processing
[//]: # (Describe how data is loaded into R and processed for analysis, starting from Raw Data)

The data we will analize is a National Oceanic and Atmospheric Administration (NOAA) storm database. This data comes in the form of a comma seperated value (csv) file compressed with the bzip2 (bz2) algorithm.
We will name data file `StormData.csv.bz2`. 
```{r}
f.data <- "StormData.csv.bz2"
```

If the data doesn't already exists in the same directory as this script, we will need to download it from the course website. Note that the `knitr` package automatically temporarilly changes the working directory to the directory of this script when executing code chunks, so there is no need to call `setwd()`. 

```{r}
if (!file.exists(f.data)) {
  f.url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
  download.file(f.url,f.data, method="curl")
}
```

We next read the data into memory. We will use `cache=TRUE` so we only have to read from the disk once during the course of analysis. 

```{r cache=TRUE}
df <- read.csv(f.data)
```

### Preprocessing
Our data set contains information about 985 different types of events, listed in the `EVTYPE` variable, which can be seen by taking a peak at the unique entries. 
```{r}
print(unique(df$EVTYPE))
```

Looking at these unique entries also raises some questions about the cleanliness of this data. For example, `TSTM WIND` represents the same thing as `THUNDERSTORM WIND` which is the same as `THUNDERSTORM WINDS`, etc. In summary, our data is not clean and not tidy. However, because this project is not designed to test how well one can clean and tidy data, so I'll just walk through a few quick proceedures to tidy things up a bit. 

The documentation for this data, [Storm Data Documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) only lists 48 different event types (see Table 1 on Page 6). I couldn't find a tablular form of this data so I copy/pasted Table 1 into a text file `EVTYPE.txt` and read it in using `read.delim` specifying a new line as the deliminator. 

```{r}
EVTYPE <- read.delim('EVTYPE.txt', header=FALSE, sep = "\n")
```
The are "[C/Z/M]" characters that indicate what type of region the event was recorded in. We want to give them their own column in our table. First we just extract the event types

```{r}
EVTYPE <- separate(EVTYPE, V1, into = "NAMES", sep="[C,Z,M]$")
```

Next we do some fuzzy matching/converstion


## Results 

[//]: # (Main results including 1--3 figures with descriptive captions)